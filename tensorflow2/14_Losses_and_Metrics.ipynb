{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","\n","from tensorflow.keras.losses import BinaryCrossentropy\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","\n","from tensorflow.keras.metrics import CategoricalAccuracy\n","from tensorflow.keras.metrics import SparseCategoricalAccuracy"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.2039724588394165\n","[[1.2039728]]\n"]}],"source":["# Binary Cross Entropy\n","\n","loss_object = BinaryCrossentropy()\n","\n","predictions = np.array([0.3]).reshape(-1, 1)\n","labels = np.array([1])\n","\n","loss = loss_object(labels, predictions)\n","loss_manual = -1 * (labels * np.log(predictions) + (1 - labels) * np.log(1 - predictions))\n","\n","print(loss.numpy())\n","print(loss_manual)"]},{"cell_type":"markdown","metadata":{},"source":["Binary Cross Entropy, Mean Squared Error 등 여러 개의 batch에 대한 losses가 나왔다면, losses의 평균 값이 cost라고 부르는 전체 loss가 된다."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.0601314306259155\n","1.0601317681000455\n"]},{"data":{"text/plain":["'\\nBinary Cross Entropy, Mean Squared Error 등 여러 개의 batch에 대한 losses가 나왔다면,\\nlosses의 평균 값이 cost라고 부르는 전체 loss가 된다.\\n'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["predictions = np.array([0.3, 0.6]).reshape(-1, 1)\n","labels = np.array([1, 0]).reshape(-1, 1)\n","\n","loss = loss_object(labels, predictions)\n","loss_manual = -1 * (labels * np.log(predictions) + (1 - labels) * np.log(1 - predictions))\n","\n","loss_manual = np.mean(loss_manual)\n","\n","print(loss.numpy())\n","print(loss_manual)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.1918502562689777\n","1.1918498277664185\n"]}],"source":["predictions = np.array([[0.3, 0.7], [0.4, 0.6], [0.1, 0.9]])\n","labels = np.array([[0, 1], [1, 0], [1, 0]])\n","\n","loss = loss_object(labels, predictions)\n","\n","loss_manual = -1 * labels * np.log(predictions)\n","loss_manual = np.sum(loss_manual, axis=1)\n","loss_manual = np.mean(loss_manual)\n","\n","print(loss_manual)\n","print(loss.numpy())"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.2877442836761475\n","1.2877442804195713\n"]}],"source":["# Categorical Cross Entropy\n","loss_object = CategoricalCrossentropy()\n","\n","predictions = np.array([[0.2, 0.1, 0.7], [0.4, 0.3, 0.3], [0.1, 0.8, 0.1]])\n","labels = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0]])\n","\n","loss = loss_object(labels, predictions)\n","\n","loss_manual = -1 * labels * np.log(predictions)\n","loss_manual = np.sum(loss_manual, axis=1)\n","loss_manual = np.mean(loss_manual)\n","\n","print(loss.numpy())\n","print(loss_manual)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.2877442836761475\n","1.2877442804195713\n"]}],"source":["# Sparse Categorical Cross Entropy\n","loss_object = SparseCategoricalCrossentropy()\n","\n","predictions = np.array([[0.2, 0.1, 0.7], [0.4, 0.3, 0.3], [0.1, 0.8, 0.1]])\n","labels = np.array([2, 1, 0])\n","\n","loss = loss_object(tf.constant(labels), tf.constant(predictions))\n","\n","ce_loss = 0\n","for data_idx in range(len(labels)):\n","  prediction = predictions[data_idx]\n","  label = labels[data_idx]\n","  \n","  t_prediction = prediction[label]\n","  ce_loss += -1 * np.log(t_prediction)\n","\n","ce_loss = ce_loss / len(labels)\n","\n","print(loss.numpy())\n","print(ce_loss)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor([0 4 1 7 8 2 1 7], shape=(8,), dtype=int64)\n"]}],"source":["import tensorflow_datasets as tfds\n","\n","train_ds = tfds.load(\n","                      name='mnist', shuffle_files=True,\n","                      as_supervised=True, split='train')\n","\n","train_ds = train_ds.batch(8)\n","\n","train_ds_iter = iter(train_ds)\n","images, labels = next(train_ds_iter)\n","\n","print(labels)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(100.0, shape=(), dtype=float32)\n"]}],"source":["metric = CategoricalAccuracy()\n","\n","predictions = np.array([[0.2, 0.2, 0.6], [0.1, 0.8, 0.1]])\n","labels = np.array([[0, 0, 1], [0, 1, 0]])\n","\n","acc = metric(labels, predictions)\n","print(acc * 100)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(50.0, shape=(), dtype=float32)\n"]}],"source":["metric = SparseCategoricalAccuracy()\n","\n","predictions = np.array([[0.2, 0.2, 0.6], [0.1, 0.8, 0.1]])\n","labels = np.array([0, 1])\n","\n","acc = metric(labels, predictions)\n","print(acc * 100)"]}],"metadata":{"interpreter":{"hash":"295b1395516e455557f2df57dc8177e4963756d54723e6022d9f229c210c60a8"},"kernelspec":{"display_name":"Python 3.8.12 64-bit ('tensor': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
