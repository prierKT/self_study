{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import optimizers\n","from termcolor import colored\n","\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Flatten, Dense, Activation\n","\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","from tensorflow.keras.optimizers import SGD, Adam\n","\n","from tensorflow.keras.metrics import Mean, SparseCategoricalAccuracy"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def get_mnist_ds():\n","  (train_validation_ds, test_ds), ds_info = tfds.load(\n","                                                      name='mnist',\n","                                                      shuffle_files=True,\n","                                                      as_supervised=True,\n","                                                      split=['train', 'test'],\n","                                                      with_info=True)\n","  \n","  n_train_validation = ds_info.splits['train'].num_examples # trainset의 데이터 수\n","  train_ratio = 0.8\n","  n_train = int(n_train_validation * train_ratio)\n","  n_validation = n_train_validation - n_train\n","  \n","  train_ds = train_validation_ds.take(n_train)\n","  remaining_ds = train_validation_ds.skip(n_train)\n","  validation_ds = remaining_ds.take(n_validation)\n","  \n","  return train_ds, validation_ds, test_ds"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def normalization(TRAIN_BATCH_SIZE, TEST_BATCH_SIZE):\n","  global train_ds, validation_ds, test_ds\n","  \n","  def stnd(images, labels):\n","    images = tf.cast(images, tf.float32) / 255.\n","    return (images, labels)\n","  \n","  train_ds = train_ds.map(stnd).shuffle(1000).batch(TRAIN_BATCH_SIZE)\n","  validation_ds = validation_ds.map(stnd).batch(TEST_BATCH_SIZE)\n","  test_ds = test_ds.map(stnd).batch(TEST_BATCH_SIZE)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class MNIST_Classifier(Model):\n","  def __init__(self):\n","    super(MNIST_Classifier, self).__init__()\n","    \n","    self.flatten = Flatten()\n","    self.d1 = Dense(units=64, activation='relu')\n","    self.d2 = Dense(units=10, activation='softmax')\n","    \n","  def call(self, x):\n","    x = self.flatten(x)\n","    x = self.d1(x)\n","    x = self.d2(x)\n","    return x"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["model = MNIST_Classifier()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def load_metrics():\n","  global train_loss, train_acc\n","  global validation_loss, validation_acc\n","  global test_loss, test_acc\n","  \n","  train_loss = Mean()\n","  validation_loss = Mean()\n","  test_loss = Mean()\n","  \n","  train_acc = SparseCategoricalAccuracy()\n","  validation_acc = SparseCategoricalAccuracy()\n","  test_acc = SparseCategoricalAccuracy()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[47m\u001b[31mEpoch\u001b[0m 1\n","Train Loss: 0.7206\t Train Accuracy: 81.85%\n","Validation Loss: 0.4177\t Validation Accuracy: 89.05%\n","\n","\u001b[47m\u001b[31mEpoch\u001b[0m 2\n","Train Loss: 0.3656\t Train Accuracy: 89.82%\n","Validation Loss: 0.3445\t Validation Accuracy: 90.42%\n","\n","\u001b[47m\u001b[31mEpoch\u001b[0m 3\n","Train Loss: 0.3131\t Train Accuracy: 91.18%\n","Validation Loss: 0.3086\t Validation Accuracy: 91.53%\n","\n","\u001b[47m\u001b[31mEpoch\u001b[0m 4\n","Train Loss: 0.2829\t Train Accuracy: 91.92%\n","Validation Loss: 0.2870\t Validation Accuracy: 92.23%\n","\n","\u001b[47m\u001b[31mEpoch\u001b[0m 5\n","Train Loss: 0.2612\t Train Accuracy: 92.56%\n","Validation Loss: 0.2658\t Validation Accuracy: 92.73%\n","\n","\u001b[47m\u001b[31mEpoch\u001b[0m 6\n","Train Loss: 0.2435\t Train Accuracy: 93.17%\n","Validation Loss: 0.2517\t Validation Accuracy: 93.12%\n","\n","\u001b[47m\u001b[31mEpoch\u001b[0m 7\n","Train Loss: 0.2285\t Train Accuracy: 93.60%\n","Validation Loss: 0.2401\t Validation Accuracy: 93.40%\n","\n","\u001b[47m\u001b[31mEpoch\u001b[0m 8\n","Train Loss: 0.2153\t Train Accuracy: 93.96%\n","Validation Loss: 0.2316\t Validation Accuracy: 93.62%\n","\n","\u001b[47m\u001b[31mEpoch\u001b[0m 9\n","Train Loss: 0.2040\t Train Accuracy: 94.25%\n","Validation Loss: 0.2187\t Validation Accuracy: 94.06%\n","\n","\u001b[47m\u001b[31mEpoch\u001b[0m 10\n","Train Loss: 0.1939\t Train Accuracy: 94.49%\n","Validation Loss: 0.2102\t Validation Accuracy: 94.11%\n","\n","\u001b[47m\u001b[31mEpoch\u001b[0m 11\n","Train Loss: 0.1847\t Train Accuracy: 94.78%\n","Validation Loss: 0.2036\t Validation Accuracy: 94.39%\n","\n","\u001b[47m\u001b[31mEpoch\u001b[0m 12\n","Train Loss: 0.1767\t Train Accuracy: 95.00%\n","Validation Loss: 0.1958\t Validation Accuracy: 94.47%\n","\n","\u001b[47m\u001b[31mEpoch\u001b[0m 13\n","Train Loss: 0.1690\t Train Accuracy: 95.20%\n","Validation Loss: 0.1905\t Validation Accuracy: 94.73%\n","\n","\u001b[47m\u001b[31mEpoch\u001b[0m 14\n","Train Loss: 0.1622\t Train Accuracy: 95.45%\n","Validation Loss: 0.1854\t Validation Accuracy: 94.88%\n","\n","\u001b[47m\u001b[31mEpoch\u001b[0m 15\n","Train Loss: 0.1560\t Train Accuracy: 95.57%\n","Validation Loss: 0.1792\t Validation Accuracy: 95.00%\n","\n","\n","=====TEST RESULT=====\n","\n","Test Loss: 0.1624\t Test Accuracy: 95.13%\n"]}],"source":["@tf.function\n","def trainer():\n","  global train_ds, model, loss_object, optimizer\n","  global train_loss, train_acc\n","  \n","  for images, labels in train_ds:\n","    with tf.GradientTape() as tape:\n","      predictions = model(images)\n","      loss = loss_object(labels, predictions)\n","      \n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    \n","    train_loss(loss)\n","    train_acc(labels, predictions)\n","\n","@tf.function\n","def validation():\n","  global validation_ds, model, loss_object\n","  global validation_loss, validation_acc\n","  \n","  for images, labels in validation_ds:\n","    predictions = model(images)\n","    loss = loss_object(labels, predictions)\n","    \n","    validation_loss(loss)\n","    validation_acc(labels, predictions)\n","\n","# @tf.function # print()를 호출하거나 debuging을 할 때에는 @tf.function은 쓰지 말 것.\n","def tester():\n","  global test_ds, model, loss_object\n","  global test_loss, test_acc\n","  \n","  for images, labels in test_ds:\n","    predictions = model(images)\n","    loss = loss_object(labels, predictions)\n","    \n","    test_loss(loss)\n","    test_acc(labels, predictions)\n","  \n","  print('\\n=====TEST RESULT=====\\n')\n","  template = 'Test Loss: {:.4f}\\t Test Accuracy: {:.2f}%'\n","  print(template.format(test_loss.result(), test_acc.result() * 100))\n","\n","\n","def train_repoter():\n","  global epoch\n","  global train_loss, train_acc\n","  global validation_loss, validation_accc\n","  \n","  print(colored('Epoch', 'red', 'on_white'), epoch + 1)\n","  \n","  template = 'Train Loss: {:.4f}\\t Train Accuracy: {:.2f}%\\nValidation Loss: {:.4f}\\t Validation Accuracy: {:.2f}%\\n'\n","  print(template.format(train_loss.result(), train_acc.result() * 100,\n","                        validation_loss.result(), validation_acc.result() * 100))\n","  \n","  train_loss.reset_states()\n","  train_acc.reset_states()\n","  validation_loss.reset_states()\n","  validation_acc.reset_states()\n","\n","EPOCHS = 15\n","LR = 0.005\n","\n","TRAIN_BATCH_SIZE = 16\n","TEST_BATCH_SIZE = 32\n","\n","train_ds, validation_ds, test_ds = get_mnist_ds()\n","normalization(TRAIN_BATCH_SIZE, TEST_BATCH_SIZE)\n","\n","model = MNIST_Classifier()\n","\n","loss_object = SparseCategoricalCrossentropy()\n","optimizer = SGD(learning_rate=LR)\n","\n","load_metrics()\n","\n","for epoch in range(EPOCHS):\n","  trainer()\n","  validation()\n","  train_repoter()\n","\n","tester()"]}],"metadata":{"interpreter":{"hash":"295b1395516e455557f2df57dc8177e4963756d54723e6022d9f229c210c60a8"},"kernelspec":{"display_name":"Python 3.8.12 64-bit ('tensor': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
